\newpage
\section{Modellazione TLM}

Le successive versioni del cifratore sono modellate usando il TLM. Il framework è stato sviluppato al di sopra di SystemC, ogni modulo TLM è un modulo di SystemC che eredita anche ulteriori interfacce. Il modulo XTEA (target) implementa anche l'interfaccia \code{ tlm::tlm\_fw\_transport\_if<>} (forward) mentre il suo testbench implementa l'interfaccia \code{ tlm::tlm\_bw\_transport\_if<>} (backward). I due moduli comunicano attraverso porte dette dette socket. Le interfacce forward devono avere al loro interno almeno una socket \emph{target} (per ricevere transazioni) e quelle backward devono avere almeno una socket \emph{initiator} (per iniziare transazioni). 

Le transazioni si scambiano sempre una struttura \code{ tlm::tlm\_generic\_payload} che al suo interno contiene un puntatore ad un oggetto definito dall'utilizzatore, che rappresenta il dato da scambiare durante la transazione. Nel nostro caso questo oggetto è un'istanza di \code{ struct Packet}. Essa ha al suo interno il comando per il target ed l'operando su cui lavorare. 

\subsection{Modellazione TLM Untimed}

Il comportamento del target è codificato nella funzione \code{b\_transport} che prende in input il \code{ tlm\_generic\_payload} ed una variabile che rappresenta il tempo. La chiamata, che verrà effettuata dall'initiator, è bloccante.

Il payload può essere di lettura o scrittura. Nel nostro caso è sempre sia di scrittura (il target esegue l'operazione) che di lettura (il target ritorna l'eventuale risultato). 

In questo caso l'informazione temporale non viene aggiornata. 

\subsection{Modellazione TLM Loosely Timed}

Questa versione differisce dalla precedente perchè viene parzialmente introdotta la gestione dell'informazione temporale. Il target nella funzione \code{ b\_transport} aggiornerà il tempo di esecuzione sommando il tempo, reale o presunto, dell'operazione richiesta dalla transazione. Si è a conoscenza del tempo reale solamente se si è già implementato il modulo a livello RTL. Nel nostro caso, possiamo settare il tempo pari a 798 cicli di clock. Il tempo di un ciclo di clock è richiesto come parametro del costruttore del target. 

La simulazione perfettamente sincronizzata dei componenti è costosa. Essa può essere velocizzata attraverso il \emph{temporal decoupling}. I processi possono essere eseguiti oltre il tempo della simulazione (non cedendo quindi il controllo allo scheduler) per un tempo massimo fissato detto \emph{quanto di tempo} o fino a che non è richiesta una sincronizzazione esplicita. Il guadagno di tempo si ottiene quindi riducendo il numero di context-switching. L'oggetto che mantiene la sincronia è detto \emph{quantum keeper}. Il metodo \code{sync} del quantum keeper cede il controllo allo scheduler. 

Il testbench conterrà quindi un oggetto della classe \code{ tlm\_utils::tlm\_quantumkeeper} che ne gestisce la sincronizzazione.

\subsection{Modellazione TLM Approximatively Timed (4 phases)}

La transazione è implementata tramite una sequenza di chiamate non bloccanti \code{nb\_transport\_[fw|bw]}, ognuna delle quali è una certa \emph{fase} della transazione. Solitamente le fasi sono quattro: \code{BEGIN\_REQ}, \code{END\_REQ}, \code{BEGIN\_RESP}, \code{END\_RESP}. Si possono comunque mettere un numero arbitrario di fasi, fino a rendere la simulazione anche precisa fino al clock. 

L'initiator chiama la forward con fase \code{BEGIN\_REQ}, e il target termina la transazione con fase \code{END\_REQ}, nel frattempo inizia a fare i calcoli per completare l'operazione richiesta. Una volta completata, il target chiama la backward con fase \code{BEGIN\_RESP} e i dati richiesti, ed l'initiator chiude la transazione con fase \code{END\_RESP}.

\subsection{Confronto delle prestazioni}

Procediamo a fare un confronto delle prestazioni delle quattro implementazioni. Ogni volta le chiavi vengono inizializzate una volta sola, poi vengono criptate e decriptate un milione di word generate casualmente. I risultati sono visibili in Tabella~\ref{tab:prestazioni}.

\begin{table}[htbp]
    \centering
    \begin{tabular}{lS[table-format=1.3,table-space-text-post = \si{\second}]S[table-format=1.3,table-space-text-post = \si{\second}]S[table-format=1.3,table-space-text-post = \si{\second}]S[table-format=3.3,table-space-text-post = \si{\second}]}
        \toprule
        & {UT} & {LT} & {AT4} & {RTL} \\\cmidrule{1-5}
        Real time   & 1.149\si{\second} & 1.757\si{\second} & 1.672\si{\second} & 174.062\si{\second} \\
        User time   & 1.144\si{\second} & 1.752\si{\second} & 1.672\si{\second} & 174.062\si{\second} \\
        System time & 0.004\si{\second} & 0.004\si{\second} & 0.000\si{\second} & 0.004\si{\second} \\\bottomrule
    \end{tabular}
    \caption{Confronto delle prestazioni}
    \label{tab:prestazioni}
\end{table}

Possiamo concludere che le prestazioni peggiori si ottengono con il modello RTL che è il più preciso. I tempi sono misurati con l'utility \code{time}.